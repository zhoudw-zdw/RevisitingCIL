2023-06-06 00:59:24,686 [trainer.py] => config: ./exps/simplecil_cifar10.json
2023-06-06 00:59:24,686 [trainer.py] => prefix:  
2023-06-06 00:59:24,686 [trainer.py] => dataset: cifar10
2023-06-06 00:59:24,686 [trainer.py] => memory_size: 0
2023-06-06 00:59:24,686 [trainer.py] => memory_per_class: 0
2023-06-06 00:59:24,686 [trainer.py] => fixed_memory: False
2023-06-06 00:59:24,686 [trainer.py] => shuffle: True
2023-06-06 00:59:24,687 [trainer.py] => init_cls: 10
2023-06-06 00:59:24,687 [trainer.py] => increment: 10
2023-06-06 00:59:24,687 [trainer.py] => model_name: simplecil
2023-06-06 00:59:24,687 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-06-06 00:59:24,687 [trainer.py] => device: [device(type='cuda', index=0)]
2023-06-06 00:59:24,687 [trainer.py] => seed: 1993
2023-06-06 00:59:24,687 [trainer.py] => tuned_epoch: 0
2023-06-06 00:59:24,687 [trainer.py] => init_lr: 0.01
2023-06-06 00:59:24,687 [trainer.py] => batch_size: 256
2023-06-06 00:59:24,687 [trainer.py] => weight_decay: 0.05
2023-06-06 00:59:24,687 [trainer.py] => min_lr: 1e-08
2023-06-06 00:59:24,687 [trainer.py] => optimizer: sgd
2023-06-06 00:59:24,687 [trainer.py] => vpt_type: shallow
2023-06-06 00:59:24,687 [trainer.py] => prompt_token_num: 3
2023-06-06 00:59:39,810 [data_manager.py] => [4, 2, 7, 6, 0, 3, 5, 8, 9, 1]
2023-06-06 01:07:42,273 [trainer.py] => config: ./exps/simplecil_cifar10.json
2023-06-06 01:07:42,273 [trainer.py] => prefix:  
2023-06-06 01:07:42,273 [trainer.py] => dataset: cifar10
2023-06-06 01:07:42,273 [trainer.py] => memory_size: 0
2023-06-06 01:07:42,273 [trainer.py] => memory_per_class: 0
2023-06-06 01:07:42,273 [trainer.py] => fixed_memory: False
2023-06-06 01:07:42,273 [trainer.py] => shuffle: True
2023-06-06 01:07:42,273 [trainer.py] => init_cls: 10
2023-06-06 01:07:42,273 [trainer.py] => increment: 10
2023-06-06 01:07:42,273 [trainer.py] => model_name: simplecil
2023-06-06 01:07:42,273 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-06-06 01:07:42,273 [trainer.py] => device: [device(type='cuda', index=0)]
2023-06-06 01:07:42,273 [trainer.py] => seed: 1993
2023-06-06 01:07:42,273 [trainer.py] => tuned_epoch: 0
2023-06-06 01:07:42,273 [trainer.py] => init_lr: 0.01
2023-06-06 01:07:42,273 [trainer.py] => batch_size: 256
2023-06-06 01:07:42,273 [trainer.py] => weight_decay: 0.05
2023-06-06 01:07:42,273 [trainer.py] => min_lr: 1e-08
2023-06-06 01:07:42,273 [trainer.py] => optimizer: sgd
2023-06-06 01:07:42,273 [trainer.py] => vpt_type: shallow
2023-06-06 01:07:42,273 [trainer.py] => prompt_token_num: 3
2023-06-06 01:07:43,300 [data_manager.py] => [4, 2, 7, 6, 0, 3, 5, 8, 9, 1]
2023-06-06 01:07:44,319 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-06-06 01:07:48,242 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-06-06 01:07:48,274 [trainer.py] => All params: 85798656
2023-06-06 01:07:48,274 [trainer.py] => Trainable params: 85798656
2023-06-06 01:07:48,667 [simplecil.py] => Learning on 0-10
