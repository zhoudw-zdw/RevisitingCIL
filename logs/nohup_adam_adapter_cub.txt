2023-06-06 01:23:44,634 [trainer.py] => config: ./exps/adam_adapter_cub.json
2023-06-06 01:23:44,634 [trainer.py] => prefix:  
2023-06-06 01:23:44,634 [trainer.py] => dataset: cub
2023-06-06 01:23:44,634 [trainer.py] => memory_size: 0
2023-06-06 01:23:44,634 [trainer.py] => memory_per_class: 0
2023-06-06 01:23:44,634 [trainer.py] => fixed_memory: False
2023-06-06 01:23:44,634 [trainer.py] => shuffle: True
2023-06-06 01:23:44,634 [trainer.py] => init_cls: 10
2023-06-06 01:23:44,634 [trainer.py] => increment: 10
2023-06-06 01:23:44,634 [trainer.py] => model_name: adam_adapter
2023-06-06 01:23:44,634 [trainer.py] => convnet_type: pretrained_vit_b16_224_adapter
2023-06-06 01:23:44,634 [trainer.py] => device: [device(type='cuda', index=0)]
2023-06-06 01:23:44,634 [trainer.py] => seed: 1993
2023-06-06 01:23:44,634 [trainer.py] => tuned_epoch: 20
2023-06-06 01:23:44,634 [trainer.py] => init_lr: 0.01
2023-06-06 01:23:44,634 [trainer.py] => batch_size: 48
2023-06-06 01:23:44,634 [trainer.py] => weight_decay: 0.0005
2023-06-06 01:23:44,634 [trainer.py] => min_lr: 0
2023-06-06 01:23:44,634 [trainer.py] => ffn_num: 64
2023-06-06 01:23:44,634 [trainer.py] => optimizer: sgd
2023-06-06 01:23:44,634 [trainer.py] => vpt_type: shallow
2023-06-06 01:23:44,634 [trainer.py] => prompt_token_num: 5
2023-06-06 01:23:44,659 [data_manager.py] => [168, 136, 51, 9, 183, 101, 171, 99, 42, 159, 191, 70, 16, 188, 27, 10, 175, 26, 68, 187, 98, 6, 85, 35, 112, 43, 100, 0, 103, 181, 88, 59, 4, 2, 116, 174, 94, 80, 106, 1, 147, 17, 141, 131, 72, 23, 173, 54, 197, 118, 87, 32, 79, 104, 91, 19, 135, 107, 178, 36, 11, 199, 142, 8, 122, 3, 28, 57, 153, 172, 190, 56, 49, 44, 97, 62, 151, 169, 194, 55, 192, 12, 189, 78, 66, 180, 15, 137, 109, 134, 92, 119, 126, 52, 170, 40, 148, 65, 144, 64, 138, 45, 77, 89, 154, 90, 71, 193, 74, 30, 113, 143, 96, 84, 67, 50, 186, 156, 69, 21, 18, 111, 108, 58, 125, 157, 150, 110, 182, 129, 166, 83, 81, 60, 13, 165, 14, 176, 63, 117, 5, 22, 145, 121, 38, 41, 82, 127, 114, 20, 31, 53, 37, 163, 196, 130, 152, 162, 86, 76, 24, 34, 184, 149, 33, 128, 198, 155, 146, 167, 139, 120, 140, 102, 47, 25, 158, 123, 46, 164, 61, 7, 115, 75, 133, 160, 105, 132, 179, 124, 48, 73, 93, 39, 95, 195, 29, 177, 185, 161]
This is for the BaseNet initialization.
I'm using ViT with adapters.
2023-06-06 01:23:46,024 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
Downloading model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]Downloading model.safetensors:   3%|▎         | 10.5M/346M [00:00<00:07, 47.2MB/s]Downloading model.safetensors:   6%|▌         | 21.0M/346M [00:00<00:05, 58.1MB/s]Downloading model.safetensors:   9%|▉         | 31.5M/346M [00:00<00:04, 68.5MB/s]Downloading model.safetensors:  15%|█▌        | 52.4M/346M [00:00<00:03, 88.1MB/s]Downloading model.safetensors:  21%|██        | 73.4M/346M [00:00<00:02, 99.1MB/s]Downloading model.safetensors:  27%|██▋       | 94.4M/346M [00:01<00:02, 105MB/s] Downloading model.safetensors:  33%|███▎      | 115M/346M [00:01<00:02, 109MB/s] Downloading model.safetensors:  39%|███▉      | 136M/346M [00:01<00:01, 112MB/s]Downloading model.safetensors:  45%|████▌     | 157M/346M [00:01<00:01, 114MB/s]Downloading model.safetensors:  51%|█████▏    | 178M/346M [00:01<00:01, 115MB/s]Downloading model.safetensors:  58%|█████▊    | 199M/346M [00:01<00:01, 115MB/s]Downloading model.safetensors:  64%|██████▎   | 220M/346M [00:02<00:01, 116MB/s]Downloading model.safetensors:  70%|██████▉   | 241M/346M [00:02<00:00, 116MB/s]Downloading model.safetensors:  76%|███████▌  | 262M/346M [00:02<00:00, 117MB/s]Downloading model.safetensors:  82%|████████▏ | 283M/346M [00:02<00:00, 117MB/s]Downloading model.safetensors:  88%|████████▊ | 304M/346M [00:02<00:00, 117MB/s]Downloading model.safetensors:  94%|█████████▍| 325M/346M [00:03<00:00, 117MB/s]Downloading model.safetensors: 100%|█████████▉| 346M/346M [00:03<00:00, 117MB/s]Downloading model.safetensors: 100%|██████████| 346M/346M [00:03<00:00, 108MB/s]
2023-06-06 01:23:49,481 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
_IncompatibleKeys(missing_keys=['blocks.0.adaptmlp.down_proj.weight', 'blocks.0.adaptmlp.down_proj.bias', 'blocks.0.adaptmlp.up_proj.weight', 'blocks.0.adaptmlp.up_proj.bias', 'blocks.1.adaptmlp.down_proj.weight', 'blocks.1.adaptmlp.down_proj.bias', 'blocks.1.adaptmlp.up_proj.weight', 'blocks.1.adaptmlp.up_proj.bias', 'blocks.2.adaptmlp.down_proj.weight', 'blocks.2.adaptmlp.down_proj.bias', 'blocks.2.adaptmlp.up_proj.weight', 'blocks.2.adaptmlp.up_proj.bias', 'blocks.3.adaptmlp.down_proj.weight', 'blocks.3.adaptmlp.down_proj.bias', 'blocks.3.adaptmlp.up_proj.weight', 'blocks.3.adaptmlp.up_proj.bias', 'blocks.4.adaptmlp.down_proj.weight', 'blocks.4.adaptmlp.down_proj.bias', 'blocks.4.adaptmlp.up_proj.weight', 'blocks.4.adaptmlp.up_proj.bias', 'blocks.5.adaptmlp.down_proj.weight', 'blocks.5.adaptmlp.down_proj.bias', 'blocks.5.adaptmlp.up_proj.weight', 'blocks.5.adaptmlp.up_proj.bias', 'blocks.6.adaptmlp.down_proj.weight', 'blocks.6.adaptmlp.down_proj.bias', 'blocks.6.adaptmlp.up_proj.weight', 'blocks.6.adaptmlp.up_proj.bias', 'blocks.7.adaptmlp.down_proj.weight', 'blocks.7.adaptmlp.down_proj.bias', 'blocks.7.adaptmlp.up_proj.weight', 'blocks.7.adaptmlp.up_proj.bias', 'blocks.8.adaptmlp.down_proj.weight', 'blocks.8.adaptmlp.down_proj.bias', 'blocks.8.adaptmlp.up_proj.weight', 'blocks.8.adaptmlp.up_proj.bias', 'blocks.9.adaptmlp.down_proj.weight', 'blocks.9.adaptmlp.down_proj.bias', 'blocks.9.adaptmlp.up_proj.weight', 'blocks.9.adaptmlp.up_proj.bias', 'blocks.10.adaptmlp.down_proj.weight', 'blocks.10.adaptmlp.down_proj.bias', 'blocks.10.adaptmlp.up_proj.weight', 'blocks.10.adaptmlp.up_proj.bias', 'blocks.11.adaptmlp.down_proj.weight', 'blocks.11.adaptmlp.down_proj.bias', 'blocks.11.adaptmlp.up_proj.weight', 'blocks.11.adaptmlp.up_proj.bias'], unexpected_keys=[])
After BaseNet initialization.
2023-06-06 01:23:49,541 [trainer.py] => All params: 86988288
2023-06-06 01:23:49,541 [trainer.py] => Trainable params: 1189632
2023-06-06 01:23:49,941 [adam_adapter.py] => Learning on 0-10
86,995,969 total parameters.
1,197,313 training parameters.
convnet.blocks.0.adaptmlp.down_proj.weight 49152
convnet.blocks.0.adaptmlp.down_proj.bias 64
convnet.blocks.0.adaptmlp.up_proj.weight 49152
convnet.blocks.0.adaptmlp.up_proj.bias 768
convnet.blocks.1.adaptmlp.down_proj.weight 49152
convnet.blocks.1.adaptmlp.down_proj.bias 64
convnet.blocks.1.adaptmlp.up_proj.weight 49152
convnet.blocks.1.adaptmlp.up_proj.bias 768
convnet.blocks.2.adaptmlp.down_proj.weight 49152
convnet.blocks.2.adaptmlp.down_proj.bias 64
convnet.blocks.2.adaptmlp.up_proj.weight 49152
convnet.blocks.2.adaptmlp.up_proj.bias 768
convnet.blocks.3.adaptmlp.down_proj.weight 49152
convnet.blocks.3.adaptmlp.down_proj.bias 64
convnet.blocks.3.adaptmlp.up_proj.weight 49152
convnet.blocks.3.adaptmlp.up_proj.bias 768
convnet.blocks.4.adaptmlp.down_proj.weight 49152
convnet.blocks.4.adaptmlp.down_proj.bias 64
convnet.blocks.4.adaptmlp.up_proj.weight 49152
convnet.blocks.4.adaptmlp.up_proj.bias 768
convnet.blocks.5.adaptmlp.down_proj.weight 49152
convnet.blocks.5.adaptmlp.down_proj.bias 64
convnet.blocks.5.adaptmlp.up_proj.weight 49152
convnet.blocks.5.adaptmlp.up_proj.bias 768
convnet.blocks.6.adaptmlp.down_proj.weight 49152
convnet.blocks.6.adaptmlp.down_proj.bias 64
convnet.blocks.6.adaptmlp.up_proj.weight 49152
convnet.blocks.6.adaptmlp.up_proj.bias 768
convnet.blocks.7.adaptmlp.down_proj.weight 49152
convnet.blocks.7.adaptmlp.down_proj.bias 64
convnet.blocks.7.adaptmlp.up_proj.weight 49152
convnet.blocks.7.adaptmlp.up_proj.bias 768
convnet.blocks.8.adaptmlp.down_proj.weight 49152
convnet.blocks.8.adaptmlp.down_proj.bias 64
convnet.blocks.8.adaptmlp.up_proj.weight 49152
convnet.blocks.8.adaptmlp.up_proj.bias 768
convnet.blocks.9.adaptmlp.down_proj.weight 49152
convnet.blocks.9.adaptmlp.down_proj.bias 64
convnet.blocks.9.adaptmlp.up_proj.weight 49152
convnet.blocks.9.adaptmlp.up_proj.bias 768
convnet.blocks.10.adaptmlp.down_proj.weight 49152
convnet.blocks.10.adaptmlp.down_proj.bias 64
convnet.blocks.10.adaptmlp.up_proj.weight 49152
convnet.blocks.10.adaptmlp.up_proj.bias 768
convnet.blocks.11.adaptmlp.down_proj.weight 49152
convnet.blocks.11.adaptmlp.down_proj.bias 64
convnet.blocks.11.adaptmlp.up_proj.weight 49152
convnet.blocks.11.adaptmlp.up_proj.bias 768
fc.weight 7680
fc.sigma 1
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 2.287, Train_accy 18.79, Test_accy 42.37:   0%|          | 0/20 [00:05<?, ?it/s]Task 0, Epoch 1/20 => Loss 2.287, Train_accy 18.79, Test_accy 42.37:   5%|▌         | 1/20 [00:05<01:45,  5.55s/it]Task 0, Epoch 2/20 => Loss 2.236, Train_accy 53.44, Test_accy 70.34:   5%|▌         | 1/20 [00:10<01:45,  5.55s/it]Task 0, Epoch 2/20 => Loss 2.236, Train_accy 53.44, Test_accy 70.34:  10%|█         | 2/20 [00:10<01:30,  5.01s/it]Task 0, Epoch 3/20 => Loss 2.159, Train_accy 77.04, Test_accy 77.12:  10%|█         | 2/20 [00:14<01:30,  5.01s/it]Task 0, Epoch 3/20 => Loss 2.159, Train_accy 77.04, Test_accy 77.12:  15%|█▌        | 3/20 [00:14<01:22,  4.85s/it]Task 0, Epoch 4/20 => Loss 2.076, Train_accy 80.58, Test_accy 80.51:  15%|█▌        | 3/20 [00:19<01:22,  4.85s/it]Task 0, Epoch 4/20 => Loss 2.076, Train_accy 80.58, Test_accy 80.51:  20%|██        | 4/20 [00:19<01:16,  4.79s/it]Task 0, Epoch 5/20 => Loss 1.974, Train_accy 83.30, Test_accy 83.90:  20%|██        | 4/20 [00:24<01:16,  4.79s/it]Task 0, Epoch 5/20 => Loss 1.974, Train_accy 83.30, Test_accy 83.90:  25%|██▌       | 5/20 [00:24<01:11,  4.76s/it]Task 0, Epoch 6/20 => Loss 1.862, Train_accy 86.64, Test_accy 90.68:  25%|██▌       | 5/20 [00:28<01:11,  4.76s/it]Task 0, Epoch 6/20 => Loss 1.862, Train_accy 86.64, Test_accy 90.68:  30%|███       | 6/20 [00:28<01:06,  4.75s/it]Task 0, Epoch 7/20 => Loss 1.739, Train_accy 86.22, Test_accy 93.22:  30%|███       | 6/20 [00:33<01:06,  4.75s/it]Task 0, Epoch 7/20 => Loss 1.739, Train_accy 86.22, Test_accy 93.22:  35%|███▌      | 7/20 [00:33<01:01,  4.73s/it]Task 0, Epoch 8/20 => Loss 1.612, Train_accy 89.35, Test_accy 93.22:  35%|███▌      | 7/20 [00:38<01:01,  4.73s/it]Task 0, Epoch 8/20 => Loss 1.612, Train_accy 89.35, Test_accy 93.22:  40%|████      | 8/20 [00:38<00:56,  4.74s/it]Task 0, Epoch 9/20 => Loss 1.497, Train_accy 88.52, Test_accy 94.07:  40%|████      | 8/20 [00:43<00:56,  4.74s/it]Task 0, Epoch 9/20 => Loss 1.497, Train_accy 88.52, Test_accy 94.07:  45%|████▌     | 9/20 [00:43<00:52,  4.75s/it]Task 0, Epoch 10/20 => Loss 1.400, Train_accy 91.44, Test_accy 94.92:  45%|████▌     | 9/20 [00:47<00:52,  4.75s/it]Task 0, Epoch 10/20 => Loss 1.400, Train_accy 91.44, Test_accy 94.92:  50%|█████     | 10/20 [00:47<00:47,  4.76s/it]Task 0, Epoch 11/20 => Loss 1.292, Train_accy 93.11, Test_accy 94.92:  50%|█████     | 10/20 [00:52<00:47,  4.76s/it]Task 0, Epoch 11/20 => Loss 1.292, Train_accy 93.11, Test_accy 94.92:  55%|█████▌    | 11/20 [00:52<00:42,  4.76s/it]Task 0, Epoch 12/20 => Loss 1.255, Train_accy 90.40, Test_accy 95.76:  55%|█████▌    | 11/20 [00:57<00:42,  4.76s/it]Task 0, Epoch 12/20 => Loss 1.255, Train_accy 90.40, Test_accy 95.76:  60%|██████    | 12/20 [00:57<00:38,  4.76s/it]Task 0, Epoch 13/20 => Loss 1.195, Train_accy 92.28, Test_accy 95.76:  60%|██████    | 12/20 [01:02<00:38,  4.76s/it]Task 0, Epoch 13/20 => Loss 1.195, Train_accy 92.28, Test_accy 95.76:  65%|██████▌   | 13/20 [01:02<00:33,  4.77s/it]Task 0, Epoch 14/20 => Loss 1.164, Train_accy 91.23, Test_accy 96.61:  65%|██████▌   | 13/20 [01:07<00:33,  4.77s/it]Task 0, Epoch 14/20 => Loss 1.164, Train_accy 91.23, Test_accy 96.61:  70%|███████   | 14/20 [01:07<00:28,  4.76s/it]Task 0, Epoch 15/20 => Loss 1.132, Train_accy 91.86, Test_accy 96.61:  70%|███████   | 14/20 [01:11<00:28,  4.76s/it]Task 0, Epoch 15/20 => Loss 1.132, Train_accy 91.86, Test_accy 96.61:  75%|███████▌  | 15/20 [01:11<00:23,  4.77s/it]Task 0, Epoch 16/20 => Loss 1.131, Train_accy 90.61, Test_accy 96.61:  75%|███████▌  | 15/20 [01:16<00:23,  4.77s/it]Task 0, Epoch 16/20 => Loss 1.131, Train_accy 90.61, Test_accy 96.61:  80%|████████  | 16/20 [01:16<00:19,  4.78s/it]Task 0, Epoch 17/20 => Loss 1.091, Train_accy 92.07, Test_accy 96.61:  80%|████████  | 16/20 [01:21<00:19,  4.78s/it]Task 0, Epoch 17/20 => Loss 1.091, Train_accy 92.07, Test_accy 96.61:  85%|████████▌ | 17/20 [01:21<00:14,  4.79s/it]Task 0, Epoch 18/20 => Loss 1.058, Train_accy 93.74, Test_accy 96.61:  85%|████████▌ | 17/20 [01:26<00:14,  4.79s/it]Task 0, Epoch 18/20 => Loss 1.058, Train_accy 93.74, Test_accy 96.61:  90%|█████████ | 18/20 [01:26<00:09,  4.79s/it]Task 0, Epoch 19/20 => Loss 1.080, Train_accy 92.48, Test_accy 96.61:  90%|█████████ | 18/20 [01:30<00:09,  4.79s/it]Task 0, Epoch 19/20 => Loss 1.080, Train_accy 92.48, Test_accy 96.61:  95%|█████████▌| 19/20 [01:30<00:04,  4.78s/it]Task 0, Epoch 20/20 => Loss 1.088, Train_accy 91.65, Test_accy 96.61:  95%|█████████▌| 19/20 [01:35<00:04,  4.78s/it]Task 0, Epoch 20/20 => Loss 1.088, Train_accy 91.65, Test_accy 96.61: 100%|██████████| 20/20 [01:35<00:00,  4.78s/it]Task 0, Epoch 20/20 => Loss 1.088, Train_accy 91.65, Test_accy 96.61: 100%|██████████| 20/20 [01:35<00:00,  4.79s/it]
2023-06-06 01:25:25,728 [adam_adapter.py] => Task 0, Epoch 20/20 => Loss 1.088, Train_accy 91.65, Test_accy 96.61
This is for the BaseNet initialization.
I'm using ViT with adapters.
2023-06-06 01:25:26,809 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2023-06-06 01:25:26,854 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
_IncompatibleKeys(missing_keys=['blocks.0.adaptmlp.down_proj.weight', 'blocks.0.adaptmlp.down_proj.bias', 'blocks.0.adaptmlp.up_proj.weight', 'blocks.0.adaptmlp.up_proj.bias', 'blocks.1.adaptmlp.down_proj.weight', 'blocks.1.adaptmlp.down_proj.bias', 'blocks.1.adaptmlp.up_proj.weight', 'blocks.1.adaptmlp.up_proj.bias', 'blocks.2.adaptmlp.down_proj.weight', 'blocks.2.adaptmlp.down_proj.bias', 'blocks.2.adaptmlp.up_proj.weight', 'blocks.2.adaptmlp.up_proj.bias', 'blocks.3.adaptmlp.down_proj.weight', 'blocks.3.adaptmlp.down_proj.bias', 'blocks.3.adaptmlp.up_proj.weight', 'blocks.3.adaptmlp.up_proj.bias', 'blocks.4.adaptmlp.down_proj.weight', 'blocks.4.adaptmlp.down_proj.bias', 'blocks.4.adaptmlp.up_proj.weight', 'blocks.4.adaptmlp.up_proj.bias', 'blocks.5.adaptmlp.down_proj.weight', 'blocks.5.adaptmlp.down_proj.bias', 'blocks.5.adaptmlp.up_proj.weight', 'blocks.5.adaptmlp.up_proj.bias', 'blocks.6.adaptmlp.down_proj.weight', 'blocks.6.adaptmlp.down_proj.bias', 'blocks.6.adaptmlp.up_proj.weight', 'blocks.6.adaptmlp.up_proj.bias', 'blocks.7.adaptmlp.down_proj.weight', 'blocks.7.adaptmlp.down_proj.bias', 'blocks.7.adaptmlp.up_proj.weight', 'blocks.7.adaptmlp.up_proj.bias', 'blocks.8.adaptmlp.down_proj.weight', 'blocks.8.adaptmlp.down_proj.bias', 'blocks.8.adaptmlp.up_proj.weight', 'blocks.8.adaptmlp.up_proj.bias', 'blocks.9.adaptmlp.down_proj.weight', 'blocks.9.adaptmlp.down_proj.bias', 'blocks.9.adaptmlp.up_proj.weight', 'blocks.9.adaptmlp.up_proj.bias', 'blocks.10.adaptmlp.down_proj.weight', 'blocks.10.adaptmlp.down_proj.bias', 'blocks.10.adaptmlp.up_proj.weight', 'blocks.10.adaptmlp.up_proj.bias', 'blocks.11.adaptmlp.down_proj.weight', 'blocks.11.adaptmlp.down_proj.bias', 'blocks.11.adaptmlp.up_proj.weight', 'blocks.11.adaptmlp.up_proj.bias'], unexpected_keys=[])
After BaseNet initialization.
Clear the convnet in MultiBranchCosineIncrementalNet, since we are using self.convnets with dual branches
pretrained_vit_b16_224
2023-06-06 01:25:27,594 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2023-06-06 01:25:27,639 [_hub.py] => [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-06-06 01:25:32,848 [trainer.py] => No NME accuracy.
2023-06-06 01:25:32,849 [trainer.py] => CNN: {'total': 98.31, '00-09': 98.31, 'old': 0, 'new': 98.31}
2023-06-06 01:25:32,849 [trainer.py] => CNN top1 curve: [98.31]
2023-06-06 01:25:32,849 [trainer.py] => CNN top5 curve: [99.15]

Average Accuracy (CNN): 98.31
2023-06-06 01:25:32,849 [trainer.py] => Average Accuracy (CNN): 98.31
2023-06-06 01:25:32,850 [trainer.py] => All params: 172802305
2023-06-06 01:25:32,851 [trainer.py] => Trainable params: 87003649
2023-06-06 01:25:32,852 [adam_adapter.py] => Learning on 10-20
2023-06-06 01:25:38,913 [trainer.py] => No NME accuracy.
2023-06-06 01:25:38,913 [trainer.py] => CNN: {'total': 97.57, '00-09': 97.46, '10-19': 97.67, 'old': 97.46, 'new': 97.67}
2023-06-06 01:25:38,913 [trainer.py] => CNN top1 curve: [98.31, 97.57]
2023-06-06 01:25:38,913 [trainer.py] => CNN top5 curve: [99.15, 99.19]

Average Accuracy (CNN): 97.94
2023-06-06 01:25:38,913 [trainer.py] => Average Accuracy (CNN): 97.94
2023-06-06 01:25:38,914 [trainer.py] => All params: 172817665
2023-06-06 01:25:38,915 [trainer.py] => Trainable params: 87019009
2023-06-06 01:25:38,916 [adam_adapter.py] => Learning on 20-30
2023-06-06 01:25:45,686 [trainer.py] => No NME accuracy.
2023-06-06 01:25:45,686 [trainer.py] => CNN: {'total': 97.09, '00-09': 96.61, '10-19': 97.67, '20-29': 96.91, 'old': 97.17, 'new': 96.91}
2023-06-06 01:25:45,686 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09]
2023-06-06 01:25:45,686 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13]

Average Accuracy (CNN): 97.65666666666668
2023-06-06 01:25:45,687 [trainer.py] => Average Accuracy (CNN): 97.65666666666668
2023-06-06 01:25:45,688 [trainer.py] => All params: 172833025
2023-06-06 01:25:45,689 [trainer.py] => Trainable params: 87034369
2023-06-06 01:25:45,690 [adam_adapter.py] => Learning on 30-40
2023-06-06 01:25:53,173 [trainer.py] => No NME accuracy.
2023-06-06 01:25:53,173 [trainer.py] => CNN: {'total': 95.15, '00-09': 94.92, '10-19': 96.12, '20-29': 96.91, '30-39': 92.73, 'old': 95.93, 'new': 92.73}
2023-06-06 01:25:53,173 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15]
2023-06-06 01:25:53,173 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12]

Average Accuracy (CNN): 97.03
2023-06-06 01:25:53,173 [trainer.py] => Average Accuracy (CNN): 97.03
2023-06-06 01:25:53,175 [trainer.py] => All params: 172848385
2023-06-06 01:25:53,177 [trainer.py] => Trainable params: 87049729
2023-06-06 01:25:53,178 [adam_adapter.py] => Learning on 40-50
2023-06-06 01:26:01,413 [trainer.py] => No NME accuracy.
2023-06-06 01:26:01,414 [trainer.py] => CNN: {'total': 93.94, '00-09': 94.92, '10-19': 96.12, '20-29': 96.91, '30-39': 89.09, '40-49': 92.52, 'old': 94.27, 'new': 92.52}
2023-06-06 01:26:01,414 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94]
2023-06-06 01:26:01,414 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93]

Average Accuracy (CNN): 96.412
2023-06-06 01:26:01,414 [trainer.py] => Average Accuracy (CNN): 96.412
2023-06-06 01:26:01,415 [trainer.py] => All params: 172863745
2023-06-06 01:26:01,416 [trainer.py] => Trainable params: 87065089
2023-06-06 01:26:01,417 [adam_adapter.py] => Learning on 50-60
2023-06-06 01:26:10,552 [trainer.py] => No NME accuracy.
2023-06-06 01:26:10,552 [trainer.py] => CNN: {'total': 91.52, '00-09': 88.14, '10-19': 95.35, '20-29': 96.91, '30-39': 89.09, '40-49': 92.52, '50-59': 87.39, 'old': 92.34, 'new': 87.39}
2023-06-06 01:26:10,553 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52]
2023-06-06 01:26:10,553 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66]

Average Accuracy (CNN): 95.59666666666668
2023-06-06 01:26:10,553 [trainer.py] => Average Accuracy (CNN): 95.59666666666668
2023-06-06 01:26:10,554 [trainer.py] => All params: 172879105
2023-06-06 01:26:10,555 [trainer.py] => Trainable params: 87080449
2023-06-06 01:26:10,556 [adam_adapter.py] => Learning on 60-70
2023-06-06 01:26:20,494 [trainer.py] => No NME accuracy.
2023-06-06 01:26:20,495 [trainer.py] => CNN: {'total': 88.82, '00-09': 87.29, '10-19': 88.37, '20-29': 96.91, '30-39': 86.36, '40-49': 91.59, '50-59': 84.68, '60-69': 87.74, 'old': 88.99, 'new': 87.74}
2023-06-06 01:26:20,495 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82]
2023-06-06 01:26:20,495 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46]

Average Accuracy (CNN): 94.62857142857145
2023-06-06 01:26:20,495 [trainer.py] => Average Accuracy (CNN): 94.62857142857145
2023-06-06 01:26:20,496 [trainer.py] => All params: 172894465
2023-06-06 01:26:20,497 [trainer.py] => Trainable params: 87095809
2023-06-06 01:26:20,498 [adam_adapter.py] => Learning on 70-80
2023-06-06 01:26:31,274 [trainer.py] => No NME accuracy.
2023-06-06 01:26:31,275 [trainer.py] => CNN: {'total': 88.9, '00-09': 87.29, '10-19': 88.37, '20-29': 96.91, '30-39': 85.45, '40-49': 91.59, '50-59': 82.88, '60-69': 87.74, '70-79': 91.49, 'old': 88.43, 'new': 91.49}
2023-06-06 01:26:31,275 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9]
2023-06-06 01:26:31,275 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59]

Average Accuracy (CNN): 93.91250000000001
2023-06-06 01:26:31,275 [trainer.py] => Average Accuracy (CNN): 93.91250000000001
2023-06-06 01:26:31,276 [trainer.py] => All params: 172909825
2023-06-06 01:26:31,277 [trainer.py] => Trainable params: 87111169
2023-06-06 01:26:31,278 [adam_adapter.py] => Learning on 80-90
2023-06-06 01:26:42,984 [trainer.py] => No NME accuracy.
2023-06-06 01:26:42,984 [trainer.py] => CNN: {'total': 89.07, '00-09': 87.29, '10-19': 86.05, '20-29': 96.91, '30-39': 85.45, '40-49': 91.59, '50-59': 81.08, '60-69': 87.74, '70-79': 91.49, '80-89': 93.98, 'old': 88.36, 'new': 93.98}
2023-06-06 01:26:42,984 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07]
2023-06-06 01:26:42,984 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67]

Average Accuracy (CNN): 93.37444444444446
2023-06-06 01:26:42,984 [trainer.py] => Average Accuracy (CNN): 93.37444444444446
2023-06-06 01:26:42,986 [trainer.py] => All params: 172925185
2023-06-06 01:26:42,986 [trainer.py] => Trainable params: 87126529
2023-06-06 01:26:42,988 [adam_adapter.py] => Learning on 90-100
2023-06-06 01:26:55,602 [trainer.py] => No NME accuracy.
2023-06-06 01:26:55,602 [trainer.py] => CNN: {'total': 88.89, '00-09': 87.29, '10-19': 86.05, '20-29': 96.91, '30-39': 80.0, '40-49': 91.59, '50-59': 81.08, '60-69': 86.79, '70-79': 91.49, '80-89': 93.98, '90-99': 92.65, 'old': 88.4, 'new': 92.65}
2023-06-06 01:26:55,602 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89]
2023-06-06 01:26:55,602 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57]

Average Accuracy (CNN): 92.92600000000002
2023-06-06 01:26:55,602 [trainer.py] => Average Accuracy (CNN): 92.92600000000002
2023-06-06 01:26:55,603 [trainer.py] => All params: 172940545
2023-06-06 01:26:55,604 [trainer.py] => Trainable params: 87141889
2023-06-06 01:26:55,605 [adam_adapter.py] => Learning on 100-110
2023-06-06 01:27:09,239 [trainer.py] => No NME accuracy.
2023-06-06 01:27:09,239 [trainer.py] => CNN: {'total': 88.1, '00-09': 87.29, '10-19': 84.5, '20-29': 94.85, '30-39': 78.18, '40-49': 91.59, '50-59': 81.08, '60-69': 86.79, '70-79': 90.78, '80-89': 93.98, '90-99': 92.65, '100-109': 86.09, 'old': 88.3, 'new': 86.09}
2023-06-06 01:27:09,239 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1]
2023-06-06 01:27:09,239 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39]

Average Accuracy (CNN): 92.48727272727274
2023-06-06 01:27:09,239 [trainer.py] => Average Accuracy (CNN): 92.48727272727274
2023-06-06 01:27:09,241 [trainer.py] => All params: 172955905
2023-06-06 01:27:09,241 [trainer.py] => Trainable params: 87157249
2023-06-06 01:27:09,243 [adam_adapter.py] => Learning on 110-120
2023-06-06 01:27:23,578 [trainer.py] => No NME accuracy.
2023-06-06 01:27:23,578 [trainer.py] => CNN: {'total': 85.59, '00-09': 86.44, '10-19': 84.5, '20-29': 94.85, '30-39': 77.27, '40-49': 90.65, '50-59': 74.77, '60-69': 85.85, '70-79': 85.11, '80-89': 91.73, '90-99': 91.18, '100-109': 85.22, '110-119': 78.76, 'old': 86.19, 'new': 78.76}
2023-06-06 01:27:23,578 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59]
2023-06-06 01:27:23,578 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16]

Average Accuracy (CNN): 91.91250000000001
2023-06-06 01:27:23,578 [trainer.py] => Average Accuracy (CNN): 91.91250000000001
2023-06-06 01:27:23,579 [trainer.py] => All params: 172971265
2023-06-06 01:27:23,580 [trainer.py] => Trainable params: 87172609
2023-06-06 01:27:23,582 [adam_adapter.py] => Learning on 120-130
2023-06-06 01:27:38,778 [trainer.py] => No NME accuracy.
2023-06-06 01:27:38,778 [trainer.py] => CNN: {'total': 84.31, '00-09': 83.9, '10-19': 83.72, '20-29': 94.85, '30-39': 76.36, '40-49': 86.92, '50-59': 74.77, '60-69': 83.96, '70-79': 84.4, '80-89': 91.73, '90-99': 90.44, '100-109': 84.35, '110-119': 78.76, '120-129': 80.37, 'old': 84.6, 'new': 80.37}
2023-06-06 01:27:38,778 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59, 84.31]
2023-06-06 01:27:38,778 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16, 98.03]

Average Accuracy (CNN): 91.3276923076923
2023-06-06 01:27:38,778 [trainer.py] => Average Accuracy (CNN): 91.3276923076923
2023-06-06 01:27:38,779 [trainer.py] => All params: 172986625
2023-06-06 01:27:38,780 [trainer.py] => Trainable params: 87187969
2023-06-06 01:27:38,782 [adam_adapter.py] => Learning on 130-140
2023-06-06 01:27:54,809 [trainer.py] => No NME accuracy.
2023-06-06 01:27:54,809 [trainer.py] => CNN: {'total': 83.73, '00-09': 83.9, '10-19': 83.72, '20-29': 94.85, '30-39': 76.36, '40-49': 86.92, '50-59': 74.77, '60-69': 83.96, '70-79': 84.4, '80-89': 90.23, '90-99': 88.24, '100-109': 84.35, '110-119': 78.76, '120-129': 75.7, '130-139': 84.75, 'old': 83.65, 'new': 84.75}
2023-06-06 01:27:54,809 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59, 84.31, 83.73]
2023-06-06 01:27:54,809 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16, 98.03, 97.81]

Average Accuracy (CNN): 90.785
2023-06-06 01:27:54,809 [trainer.py] => Average Accuracy (CNN): 90.785
2023-06-06 01:27:54,810 [trainer.py] => All params: 173001985
2023-06-06 01:27:54,811 [trainer.py] => Trainable params: 87203329
2023-06-06 01:27:54,813 [adam_adapter.py] => Learning on 140-150
2023-06-06 01:28:11,529 [trainer.py] => No NME accuracy.
2023-06-06 01:28:11,529 [trainer.py] => CNN: {'total': 82.68, '00-09': 83.9, '10-19': 82.95, '20-29': 93.81, '30-39': 76.36, '40-49': 84.11, '50-59': 74.77, '60-69': 83.96, '70-79': 83.69, '80-89': 90.23, '90-99': 86.76, '100-109': 83.48, '110-119': 76.99, '120-129': 75.7, '130-139': 84.75, '140-149': 77.78, 'old': 83.06, 'new': 77.78}
2023-06-06 01:28:11,530 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59, 84.31, 83.73, 82.68]
2023-06-06 01:28:11,530 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16, 98.03, 97.81, 97.74]

Average Accuracy (CNN): 90.24466666666667
2023-06-06 01:28:11,530 [trainer.py] => Average Accuracy (CNN): 90.24466666666667
2023-06-06 01:28:11,531 [trainer.py] => All params: 173017345
2023-06-06 01:28:11,532 [trainer.py] => Trainable params: 87218689
2023-06-06 01:28:11,534 [adam_adapter.py] => Learning on 150-160
2023-06-06 01:28:29,264 [trainer.py] => No NME accuracy.
2023-06-06 01:28:29,264 [trainer.py] => CNN: {'total': 82.76, '00-09': 83.05, '10-19': 81.4, '20-29': 93.81, '30-39': 76.36, '40-49': 84.11, '50-59': 74.77, '60-69': 83.96, '70-79': 82.98, '80-89': 90.23, '90-99': 84.56, '100-109': 81.74, '110-119': 76.99, '120-129': 75.7, '130-139': 83.9, '140-149': 77.78, '150-159': 91.94, 'old': 82.12, 'new': 91.94}
2023-06-06 01:28:29,264 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59, 84.31, 83.73, 82.68, 82.76]
2023-06-06 01:28:29,264 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16, 98.03, 97.81, 97.74, 97.67]

Average Accuracy (CNN): 89.776875
2023-06-06 01:28:29,264 [trainer.py] => Average Accuracy (CNN): 89.776875
2023-06-06 01:28:29,265 [trainer.py] => All params: 173032705
2023-06-06 01:28:29,266 [trainer.py] => Trainable params: 87234049
2023-06-06 01:28:29,268 [adam_adapter.py] => Learning on 160-170
2023-06-06 01:28:47,901 [trainer.py] => No NME accuracy.
2023-06-06 01:28:47,901 [trainer.py] => CNN: {'total': 82.37, '00-09': 82.2, '10-19': 80.62, '20-29': 93.81, '30-39': 76.36, '40-49': 84.11, '50-59': 74.77, '60-69': 83.96, '70-79': 80.85, '80-89': 90.23, '90-99': 84.56, '100-109': 81.74, '110-119': 76.99, '120-129': 75.7, '130-139': 83.9, '140-149': 75.4, '150-159': 91.94, '160-169': 82.84, 'old': 82.34, 'new': 82.84}
2023-06-06 01:28:47,901 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59, 84.31, 83.73, 82.68, 82.76, 82.37]
2023-06-06 01:28:47,901 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16, 98.03, 97.81, 97.74, 97.67, 97.53]

Average Accuracy (CNN): 89.34117647058825
2023-06-06 01:28:47,901 [trainer.py] => Average Accuracy (CNN): 89.34117647058825
2023-06-06 01:28:47,902 [trainer.py] => All params: 173048065
2023-06-06 01:28:47,903 [trainer.py] => Trainable params: 87249409
2023-06-06 01:28:47,905 [adam_adapter.py] => Learning on 170-180
2023-06-06 01:29:07,523 [trainer.py] => No NME accuracy.
2023-06-06 01:29:07,523 [trainer.py] => CNN: {'total': 82.1, '00-09': 81.36, '10-19': 80.62, '20-29': 93.81, '30-39': 76.36, '40-49': 84.11, '50-59': 74.77, '60-69': 83.96, '70-79': 80.85, '80-89': 90.23, '90-99': 84.56, '100-109': 81.74, '110-119': 75.22, '120-129': 72.9, '130-139': 83.9, '140-149': 74.6, '150-159': 91.94, '160-169': 82.84, '170-179': 83.5, 'old': 82.02, 'new': 83.5}
2023-06-06 01:29:07,524 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59, 84.31, 83.73, 82.68, 82.76, 82.37, 82.1]
2023-06-06 01:29:07,524 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16, 98.03, 97.81, 97.74, 97.67, 97.53, 97.13]

Average Accuracy (CNN): 88.9388888888889
2023-06-06 01:29:07,524 [trainer.py] => Average Accuracy (CNN): 88.9388888888889
2023-06-06 01:29:07,525 [trainer.py] => All params: 173063425
2023-06-06 01:29:07,525 [trainer.py] => Trainable params: 87264769
2023-06-06 01:29:07,528 [adam_adapter.py] => Learning on 180-190
2023-06-06 01:29:27,743 [trainer.py] => No NME accuracy.
2023-06-06 01:29:27,743 [trainer.py] => CNN: {'total': 81.73, '00-09': 81.36, '10-19': 80.62, '20-29': 91.75, '30-39': 76.36, '40-49': 83.18, '50-59': 74.77, '60-69': 83.96, '70-79': 80.85, '80-89': 90.23, '90-99': 83.82, '100-109': 81.74, '110-119': 75.22, '120-129': 71.03, '130-139': 83.05, '140-149': 74.6, '150-159': 91.94, '160-169': 82.84, '170-179': 83.5, '180-189': 81.06, 'old': 81.77, 'new': 81.06}
2023-06-06 01:29:27,743 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59, 84.31, 83.73, 82.68, 82.76, 82.37, 82.1, 81.73]
2023-06-06 01:29:27,743 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16, 98.03, 97.81, 97.74, 97.67, 97.53, 97.13, 96.73]

Average Accuracy (CNN): 88.55947368421053
2023-06-06 01:29:27,743 [trainer.py] => Average Accuracy (CNN): 88.55947368421053
2023-06-06 01:29:27,744 [trainer.py] => All params: 173078785
2023-06-06 01:29:27,745 [trainer.py] => Trainable params: 87280129
2023-06-06 01:29:27,747 [adam_adapter.py] => Learning on 190-200
2023-06-06 01:29:49,003 [trainer.py] => No NME accuracy.
2023-06-06 01:29:49,003 [trainer.py] => CNN: {'total': 80.7, '00-09': 81.36, '10-19': 79.84, '20-29': 91.75, '30-39': 75.45, '40-49': 83.18, '50-59': 73.87, '60-69': 80.19, '70-79': 78.72, '80-89': 90.23, '90-99': 83.09, '100-109': 81.74, '110-119': 75.22, '120-129': 71.03, '130-139': 83.05, '140-149': 74.6, '150-159': 91.94, '160-169': 79.85, '170-179': 83.5, '180-189': 80.3, '190-199': 73.47, 'old': 81.02, 'new': 73.47}
2023-06-06 01:29:49,003 [trainer.py] => CNN top1 curve: [98.31, 97.57, 97.09, 95.15, 93.94, 91.52, 88.82, 88.9, 89.07, 88.89, 88.1, 85.59, 84.31, 83.73, 82.68, 82.76, 82.37, 82.1, 81.73, 80.7]
2023-06-06 01:29:49,003 [trainer.py] => CNN top5 curve: [99.15, 99.19, 99.13, 99.12, 98.93, 98.66, 98.46, 98.59, 98.67, 98.57, 98.39, 98.16, 98.03, 97.81, 97.74, 97.67, 97.53, 97.13, 96.73, 96.65]

Average Accuracy (CNN): 88.16650000000001
2023-06-06 01:29:49,003 [trainer.py] => Average Accuracy (CNN): 88.16650000000001
